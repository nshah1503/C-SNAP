{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NDupTFM-ZuWl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_file_path = '/Users/prabaljitwalia/Downloads/AG-NEWS/train.csv'\n",
        "test_file_path = '/Users/prabaljitwalia/Downloads/AG-NEWS/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_file_path)\n",
        "test_df = pd.read_csv(test_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /Applications/anaconda3/lib/python3.11/site-packages (2.15.0)\n",
            "Requirement already satisfied: keras in /Applications/anaconda3/lib/python3.11/site-packages (2.15.0)\n",
            "Requirement already satisfied: scikit-learn in /Applications/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
            "Requirement already satisfied: pandas in /Applications/anaconda3/lib/python3.11/site-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /Applications/anaconda3/lib/python3.11/site-packages (1.24.3)\n",
            "Requirement already satisfied: tensorflow-macos==2.15.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (68.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /Applications/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Applications/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Applications/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Applications/anaconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Applications/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.23.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Applications/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Applications/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Applications/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Applications/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Applications/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Applications/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow keras scikit-learn pandas numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nlpaug in /Applications/anaconda3/lib/python3.11/site-packages (1.1.11)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /Applications/anaconda3/lib/python3.11/site-packages (from nlpaug) (1.24.3)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /Applications/anaconda3/lib/python3.11/site-packages (from nlpaug) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /Applications/anaconda3/lib/python3.11/site-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from nlpaug) (4.7.1)\n",
            "Requirement already satisfied: filelock in /Applications/anaconda3/lib/python3.11/site-packages (from gdown>=4.0.0->nlpaug) (3.9.0)\n",
            "Requirement already satisfied: six in /Applications/anaconda3/lib/python3.11/site-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /Applications/anaconda3/lib/python3.11/site-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /Applications/anaconda3/lib/python3.11/site-packages (from gdown>=4.0.0->nlpaug) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Applications/anaconda3/lib/python3.11/site-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Applications/anaconda3/lib/python3.11/site-packages (from pandas>=1.2.0->nlpaug) (2022.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Applications/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Applications/anaconda3/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install nlpaug\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RhlFgHFFa2QD",
        "outputId": "3d1f4f12-4609-4d60-e602-ebdcb175c6f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Index</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
              "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
              "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Class Index                                              Title  \\\n",
              "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
              "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
              "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
              "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
              "4            3  Oil prices soar to all-time record, posing new...   \n",
              "\n",
              "                                         Description  \n",
              "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
              "1  Reuters - Private investment firm Carlyle Grou...  \n",
              "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
              "3  Reuters - Authorities have halted oil export\\f...  \n",
              "4  AFP - Tearaway world oil prices, toppling reco...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hVn5iL3qbMnD",
        "outputId": "8b0f79a3-9d33-428c-a343-9277e0af6a08"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Index</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Fears for T N pension after talks</td>\n",
              "      <td>Unions representing workers at Turner   Newall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
              "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
              "      <td>AP - A company founded by a chemistry research...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
              "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
              "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Class Index                                              Title  \\\n",
              "0            3                  Fears for T N pension after talks   \n",
              "1            4  The Race is On: Second Private Team Sets Launc...   \n",
              "2            4      Ky. Company Wins Grant to Study Peptides (AP)   \n",
              "3            4      Prediction Unit Helps Forecast Wildfires (AP)   \n",
              "4            4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
              "\n",
              "                                         Description  \n",
              "0  Unions representing workers at Turner   Newall...  \n",
              "1  SPACE.com - TORONTO, Canada -- A second\\team o...  \n",
              "2  AP - A company founded by a chemistry research...  \n",
              "3  AP - It's barely dawn when Mike Fitzpatrick st...  \n",
              "4  AP - Southern California's smog-fighting agenc...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Hy6Vnd9jgBM7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_df['text'] = train_df['Title'] + ' ' + train_df['Description']\n",
        "test_df['text'] = test_df['Title'] + ' ' + test_df['Description']\n",
        "\n",
        "# Tokenization with N-grams\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(train_df['text'])\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_df['text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_df['text'])\n",
        "\n",
        "# Padding\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=500)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=500)\n",
        "\n",
        "# Prepare labels\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(train_df['Class Index'])\n",
        "y_train = to_categorical(integer_encoded)\n",
        "labels = to_categorical(integer_encoded)\n",
        "\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_padded, y_train, test_size=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 500, 100)          7033800   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 496, 64)           32064     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 99, 64)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7099148 (27.08 MB)\n",
            "Trainable params: 7099148 (27.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense\n",
        "\n",
        "VOCAB_SIZE = len(word_index) + 1\n",
        "EMBEDDING_DIM = 100\n",
        "MAX_SEQUENCE_LENGTH = 500\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(labels.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "3000/3000 [==============================] - 134s 45ms/step - loss: 0.3340 - accuracy: 0.8830 - val_loss: 0.2704 - val_accuracy: 0.9071\n",
            "Epoch 2/3\n",
            "3000/3000 [==============================] - 133s 44ms/step - loss: 0.2314 - accuracy: 0.9198 - val_loss: 0.2694 - val_accuracy: 0.9085\n",
            "Epoch 3/3\n",
            "3000/3000 [==============================] - 134s 45ms/step - loss: 0.1835 - accuracy: 0.9358 - val_loss: 0.2815 - val_accuracy: 0.9045\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, batch_size=32, epochs=3, validation_data=(X_val, y_val))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "238/238 [==============================] - 3s 11ms/step - loss: 0.2923 - accuracy: 0.9011\n",
            "Test Accuracy: 90.11%, Test Loss: 0.2923\n",
            "238/238 [==============================] - 3s 10ms/step\n",
            "Confusion Matrix:\n",
            "[[1696   60   97   47]\n",
            " [  25 1831   23   21]\n",
            " [  49   14 1724  113]\n",
            " [  69   15  219 1597]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.89      0.91      1900\n",
            "           1       0.95      0.96      0.96      1900\n",
            "           2       0.84      0.91      0.87      1900\n",
            "           3       0.90      0.84      0.87      1900\n",
            "\n",
            "    accuracy                           0.90      7600\n",
            "   macro avg       0.90      0.90      0.90      7600\n",
            "weighted avg       0.90      0.90      0.90      7600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_df['text'])\n",
        "X_test = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_test = to_categorical(label_encoder.transform(test_df['Class Index']))\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%, Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(true_classes, predicted_classes))\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_classes, predicted_classes))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CoreML\n",
        "this is a technique to transform our model to coreml acceptable format for the app (We tried to use this instead of building custom backend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Applications/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('text_classification_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: coremltools in /Applications/anaconda3/lib/python3.11/site-packages (7.1)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /Applications/anaconda3/lib/python3.11/site-packages (from coremltools) (1.24.3)\n",
            "Requirement already satisfied: protobuf<=4.0.0,>=3.1.0 in /Applications/anaconda3/lib/python3.11/site-packages (from coremltools) (3.20.3)\n",
            "Requirement already satisfied: sympy in /Applications/anaconda3/lib/python3.11/site-packages (from coremltools) (1.11.1)\n",
            "Requirement already satisfied: tqdm in /Applications/anaconda3/lib/python3.11/site-packages (from coremltools) (4.65.0)\n",
            "Requirement already satisfied: packaging in /Applications/anaconda3/lib/python3.11/site-packages (from coremltools) (23.0)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /Applications/anaconda3/lib/python3.11/site-packages (from coremltools) (23.1.0)\n",
            "Requirement already satisfied: cattrs in /Applications/anaconda3/lib/python3.11/site-packages (from coremltools) (23.2.2)\n",
            "Requirement already satisfied: pyaml in /Applications/anaconda3/lib/python3.11/site-packages (from coremltools) (23.9.7)\n",
            "Requirement already satisfied: PyYAML in /Applications/anaconda3/lib/python3.11/site-packages (from pyaml->coremltools) (6.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Applications/anaconda3/lib/python3.11/site-packages (from sympy->coremltools) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install coremltools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "When both 'convert_to' and 'minimum_deployment_target' not specified, 'convert_to' is set to \"mlprogram\" and 'minimum_deployment_targer' is set to ct.target.iOS15 (which is same as ct.target.macOS12). Note: the model will not run on systems older than iOS15/macOS12/watchOS8/tvOS15. In order to make your model run on older system, please set the 'minimum_deployment_target' to iOS14/iOS13. Details please see the link: https://coremltools.readme.io/docs/unified-conversion-api#target-conversion-formats\n",
            "Running TensorFlow Graph Passes: 100%|███████| 6/6 [00:00<00:00,  9.98 passes/s]\n",
            "Converting TF Frontend ==> MIL Ops:   0%|              | 0/63 [00:00<?, ? ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
            "Converting TF Frontend ==> MIL Ops: 100%|█| 14/14 [00:00<00:00, 126280.12 ops/s]\n",
            "Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
            "Converting TF Frontend ==> MIL Ops: 100%|██| 41/41 [00:00<00:00, 23495.90 ops/s]\n",
            "Converting TF Frontend ==> MIL Ops: 100%|██| 14/14 [00:00<00:00, 96579.37 ops/s]\n",
            "Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
            "Converting TF Frontend ==> MIL Ops: 100%|██| 41/41 [00:00<00:00, 23631.51 ops/s]\n",
            "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
            "Converting TF Frontend ==> MIL Ops: 100%|███| 63/63 [00:00<00:00, 3331.96 ops/s]\n",
            "Running MIL frontend_tensorflow2 pipeline: 100%|█| 7/7 [00:00<00:00, 3046.29 pas\n",
            "Running MIL default pipeline: 100%|███████| 71/71 [00:00<00:00, 399.00 passes/s]\n",
            "Running MIL backend_mlprogram pipeline: 100%|█| 12/12 [00:00<00:00, 4063.59 pass\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import coremltools as ct\n",
        "\n",
        "# Load the Keras model\n",
        "keras_model = tf.keras.models.load_model('text_classification_model.h5')\n",
        "\n",
        "# Convert to Core ML\n",
        "coreml_model = ct.convert(keras_model, source='tensorflow')\n",
        "coreml_model.save('TextClassification.mlpackage')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary: openAI has reached an \"agreement in principle\" for Altman’s return. the startup is also reforming its board, eliminating members who faced scrutiny. former Salesforce co-chief executive Bret Taylor, former secretary of the u.s. Treasury Larry Summers and Quora founder Adam D’Angelo will be part of the new board.\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import re\n",
        "\n",
        "model_name = \"t5-base\"  \n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)  \n",
        "    text = text.strip()  \n",
        "    return text\n",
        "\n",
        "def summarize_text(text, max_length=250, min_length=50, length_penalty=2.0, num_beams=4):\n",
        "    text = clean_text(text) \n",
        "    input_text = \"summarize: \" + text\n",
        "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=length_penalty, num_beams=num_beams, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Example \n",
        "example_text = \"\"\" Sam Altman is returning to OpenAI as its chief executive, the high-profile AI startup said Wednesday, a dramatic reversal that caps an intense five days of discussions, debates and convincing following the sudden dismissal of Altman last week from the startup he co-founded.\n",
        "OpenAI, which is the most valuable U.S. startup, said it has reached an “agreement in principle” for Altman’s return. The startup is also reforming its board, eliminating several members who faced intense scrutiny for their decision last week.\n",
        "Former Salesforce co-chief executive Bret Taylor, former U.S. Secretary of the Treasury Larry Summers, and Quora founder Adam D’Angelo will be part of the new board at the AI startup. Taylor will serve as the chair of the board, the startup said.\n",
        "Microsoft, which has invested over $11 billion in OpenAI and owns about 49% of the startup, was taken aback by OpenAI’s decision last week and rushed to hire Altman to lead a new AI group at the software conglomerate. Greg Brockman, former President of OpenAI, and countless other members of the startup resigned in protest of the earlier OpenAI board’s decision. Brockman, who had also joined Microsoft, said he was also returning to the startup.\n",
        "In response to OpenAI’s move Wednesday, Altman said: “I love OpenAI, and everything I’ve done over the past few days has been in service of keeping this team and its mission together. when I decided to join Microsoft on Sunday evening, it was clear that was the best path for me and the team. With the new board and with Satya’s support, I’m looking forward to returning to OpenAI, and building on our strong partnership with Microsoft.”\n",
        "Microsoft chief Satya Nadella, who also expressed disappointment in OpenAI board’s decision last week and pledged to ensure that Microsoft would never be “surprised” again, said Wednesday that he was encouraged by today’s changes to the OpenAI board.\n",
        "“We believe this is a first essential step on a path to more stable, well-informed, and effective governance. Sam, Greg, and I have talked and agreed they have a key role to play along with the OAI leadership team in ensuring OAI continues to thrive and build on its mission. We look forward to building on our strong partnership and delivering the value of this next generation of AI to our customers and partners.”\n",
        "Nadella said in television interviews earlier this week that he had earlier relayed to the OpenAI board of directors that Microsoft will be working with Altman and Brockman “either way.” He also didn’t rule out the possibility of Altman and Brockman returning to OpenAI and said Microsoft will remain committed to the startup, which through its ChatGPT platform has captured the attention of the world in a way very few technologies have in the past.\n",
        "OpenAI isn’t only widely estimated to be leading the current AI race but also has in less than a year assumed the position of kingmaker for thousands of other startups that are building atop its software offerings. Investment in OpenAI has also supercharged Microsoft’s AI efforts, helping it court many businesses and bolstering Wall Street’s positive outlook on Microsoft’s future.\n",
        "OpenAI’s earlier board — which included its chief scientist Ilya Sutskever, independent directors D’Angelo, technology entrepreneur Tasha McCauley, and Georgetown Center for Security and Emerging Technology’s Helen Toner — faced intense public scrutiny for their abrupt decision, for which they never offered a comprehensive explanation. Growing frustrated with the earlier OpenAI board, several OpenAI investors began exploring options to sue the board members, Reuters reported Tuesday.\n",
        "Joshua Kushner, founder of Thrive Capital, a backer of OpenAI, who had pushed for Altman’s return, said Wednesday that the startup has the “potential to be one of the most consequential companies in the history of computing.” Altman and Brockman “possess a profound commitment to the company’s integrity, and an unmatched ability to inspire and lead. We couldn’t be more excited for them to come back to the company they founded and helped build into what it is today.”\n",
        "“The resilience and strength we have seen from the entire OpenAI team in the past few days has been extraordinary, and we consider it a true honor to be their partners now and in the future. We believe this is the best outcome for the company, its employees, those who build on their technologies, and the world at large.”\n",
        "Emmett Shear, the former Twitch chief executive who was appointed as interim leader of OpenAI on Sunday, said he was pleased with OpenAI’s new decision. “Coming into OpenAI, I wasn’t sure what the right path would be. This was the pathway that maximized safety alongside doing right by all stakeholders involved. I’m glad to have been a part of the solution,” he posted on X.\n",
        "\"\"\"\n",
        "summary = summarize_text(example_text)\n",
        "print(\"Summary:\", summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing raw input with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(raw_text, tokenizer, max_sequence_length):\n",
        "    sequence = tokenizer.texts_to_sequences([raw_text])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length)\n",
        "    return padded_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_text_class(model, processed_text, label_encoder):\n",
        "    prediction = model.predict(processed_text)\n",
        "    predicted_class_index = np.argmax(prediction, axis=1)\n",
        "    predicted_class = label_encoder.inverse_transform(predicted_class_index)\n",
        "    return predicted_class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n",
            "Predicted class: 2\n"
          ]
        }
      ],
      "source": [
        "input_text = \"Michigana-Ohio State: Wolverines outlast Buckeyes for third win in a row against rivals\"\n",
        "\n",
        "processed_text = preprocess_text(input_text, tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "predicted_class = predict_text_class(model, processed_text, label_encoder)\n",
        "print(\"Predicted class:\", predicted_class[0])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
